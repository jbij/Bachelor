{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial step: From data we need to create graph of cocuring hashtags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_json(\"../shared-folder-gald/data/video-creators.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>video_description</th>\n",
       "      <th>region_code</th>\n",
       "      <th>share_count</th>\n",
       "      <th>hashtag_names</th>\n",
       "      <th>id</th>\n",
       "      <th>like_count</th>\n",
       "      <th>music_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>voice_to_text</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>create_time</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster-label</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>effect_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the.animal.holocaust</td>\n",
       "      <td>Replying to @ov10bronco #dominicizrealmyers #v...</td>\n",
       "      <td>US</td>\n",
       "      <td>4</td>\n",
       "      <td>[vegan, yes, bbq, meat, carnivore, govegan, ve...</td>\n",
       "      <td>7274212644502998314</td>\n",
       "      <td>40</td>\n",
       "      <td>7.274213e+18</td>\n",
       "      <td>1054</td>\n",
       "      <td>You say, why torture yourself? Because all we ...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2023-09-02 13:00:37</td>\n",
       "      <td>10</td>\n",
       "      <td>Healthy Cooking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bakemehealthylove</td>\n",
       "      <td>How to make: 1. Get Your Mix: Grab our Oatmeal...</td>\n",
       "      <td>US</td>\n",
       "      <td>4</td>\n",
       "      <td>[wafflemix, waffleday, plantbased, strawberryw...</td>\n",
       "      <td>7271102720256314666</td>\n",
       "      <td>65</td>\n",
       "      <td>7.217848e+18</td>\n",
       "      <td>1087</td>\n",
       "      <td>Happy National Waffle Day we're celebrating wi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-25 03:52:14</td>\n",
       "      <td>10</td>\n",
       "      <td>Healthy Cooking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livinapril7</td>\n",
       "      <td>Looking for a healthy #plantbased #protein pac...</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>[food, healthy, lunch, health, salad, tasty, o...</td>\n",
       "      <td>7272105378920353054</td>\n",
       "      <td>2</td>\n",
       "      <td>6.705026e+18</td>\n",
       "      <td>271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-27 20:43:20</td>\n",
       "      <td>10</td>\n",
       "      <td>Healthy Cooking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goodvibessocietyofficial</td>\n",
       "      <td>Pull up to Sprouts, grab those good vibes bott...</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>[drinks, weekendvibes, sprouts, plantbased, su...</td>\n",
       "      <td>7271427012529524011</td>\n",
       "      <td>31</td>\n",
       "      <td>7.271427e+18</td>\n",
       "      <td>372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-08-26 00:50:41</td>\n",
       "      <td>-1</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>settonfarms</td>\n",
       "      <td>At Setton Farms, we are committed to sustainab...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>[nuts, recipe, farm, farmlife, harvest, pistac...</td>\n",
       "      <td>7273980908565433646</td>\n",
       "      <td>120</td>\n",
       "      <td>7.133309e+18</td>\n",
       "      <td>7031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-09-01 22:01:08</td>\n",
       "      <td>8</td>\n",
       "      <td>Gardening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   username  \\\n",
       "0      the.animal.holocaust   \n",
       "1         bakemehealthylove   \n",
       "2               livinapril7   \n",
       "3  goodvibessocietyofficial   \n",
       "4               settonfarms   \n",
       "\n",
       "                                   video_description region_code  share_count  \\\n",
       "0  Replying to @ov10bronco #dominicizrealmyers #v...          US            4   \n",
       "1  How to make: 1. Get Your Mix: Grab our Oatmeal...          US            4   \n",
       "2  Looking for a healthy #plantbased #protein pac...          US            0   \n",
       "3  Pull up to Sprouts, grab those good vibes bott...          US            0   \n",
       "4  At Setton Farms, we are committed to sustainab...          US            1   \n",
       "\n",
       "                                       hashtag_names                   id  \\\n",
       "0  [vegan, yes, bbq, meat, carnivore, govegan, ve...  7274212644502998314   \n",
       "1  [wafflemix, waffleday, plantbased, strawberryw...  7271102720256314666   \n",
       "2  [food, healthy, lunch, health, salad, tasty, o...  7272105378920353054   \n",
       "3  [drinks, weekendvibes, sprouts, plantbased, su...  7271427012529524011   \n",
       "4  [nuts, recipe, farm, farmlife, harvest, pistac...  7273980908565433646   \n",
       "\n",
       "   like_count      music_id  view_count  \\\n",
       "0          40  7.274213e+18        1054   \n",
       "1          65  7.217848e+18        1087   \n",
       "2           2  6.705026e+18         271   \n",
       "3          31  7.271427e+18         372   \n",
       "4         120  7.133309e+18        7031   \n",
       "\n",
       "                                       voice_to_text  comment_count  \\\n",
       "0  You say, why torture yourself? Because all we ...          181.0   \n",
       "1  Happy National Waffle Day we're celebrating wi...            0.0   \n",
       "2                                                NaN            0.0   \n",
       "3                                                NaN            2.0   \n",
       "4                                                NaN            2.0   \n",
       "\n",
       "          create_time  cluster    cluster-label  playlist_id effect_ids  \n",
       "0 2023-09-02 13:00:37       10  Healthy Cooking          NaN        NaN  \n",
       "1 2023-08-25 03:52:14       10  Healthy Cooking          NaN        NaN  \n",
       "2 2023-08-27 20:43:20       10  Healthy Cooking          NaN        NaN  \n",
       "3 2023-08-26 00:50:41       -1         Outliers          NaN        NaN  \n",
       "4 2023-09-01 22:01:08        8        Gardening          NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtag_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7151417313785335045</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7151417313785335045</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7151417313785335045</td>\n",
       "      <td>gardening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7151417313785335045</td>\n",
       "      <td>gardeners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7151417313785335045</td>\n",
       "      <td>organicgardening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856020</th>\n",
       "      <td>7426010179746991391</td>\n",
       "      <td>atlanticforest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856021</th>\n",
       "      <td>7426085565751184672</td>\n",
       "      <td>nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856022</th>\n",
       "      <td>7426085565751184672</td>\n",
       "      <td>construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856023</th>\n",
       "      <td>7426085565751184672</td>\n",
       "      <td>hempcrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856024</th>\n",
       "      <td>7426085565751184672</td>\n",
       "      <td>sustainablebuilding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8856025 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id        hashtag_names\n",
       "0        7151417313785335045               autumn\n",
       "1        7151417313785335045                 fall\n",
       "2        7151417313785335045            gardening\n",
       "3        7151417313785335045            gardeners\n",
       "4        7151417313785335045     organicgardening\n",
       "...                      ...                  ...\n",
       "8856020  7426010179746991391       atlanticforest\n",
       "8856021  7426085565751184672               nature\n",
       "8856022  7426085565751184672         construction\n",
       "8856023  7426085565751184672            hempcrete\n",
       "8856024  7426085565751184672  sustainablebuilding\n",
       "\n",
       "[8856025 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_dict = videos.groupby('id')['hashtag_names'].apply(list).to_dict()\n",
    "\n",
    "hashtag_set = [(video, hashtag) for video, hashtags in hashtag_dict.items() for hashtag in hashtags[0]]\n",
    "\n",
    "# Create a DataFrame\n",
    "hashtag_df = pd.DataFrame(hashtag_set, columns=['id', 'hashtag_names'])\n",
    "hashtag_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original unique hashtags: 673697\n",
      "Filtered unique hashtags: 286836\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame (assuming it's already loaded)\n",
    "# hashtag_df = pd.read_csv(\"your_data.csv\")  # Load your data if needed\n",
    "\n",
    "# Count occurrences of each hashtag\n",
    "hashtag_counts = hashtag_df[\"hashtag_names\"].value_counts()\n",
    "\n",
    "# Define a threshold (e.g., keep only hashtags that appear at least 100 times)\n",
    "threshold = 2  \n",
    "frequent_hashtags = hashtag_counts[hashtag_counts >= threshold]\n",
    "\n",
    "# Filter the original DataFrame\n",
    "filtered_df = hashtag_df[hashtag_df[\"hashtag_names\"].isin(frequent_hashtags.index)]\n",
    "\n",
    "# Display results\n",
    "print(f\"Original unique hashtags: {hashtag_df['hashtag_names'].nunique()}\")\n",
    "print(f\"Filtered unique hashtags: {filtered_df['hashtag_names'].nunique()}\")\n",
    "\n",
    "# Save or use the filtered data\n",
    "# filtered_df.to_csv(\"filtered_hashtags.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as CSV\n",
    "# filtered_df.to_csv(\"edgelist_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bipartitre graph for videos-hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNFILTERED GRAPH\n",
    "# G = nx.Graph()\n",
    "# #for nodes\n",
    "\n",
    "# video_ids = set(hashtag_df['id'])\n",
    "# hashtags = set(hashtag_df['hashtag_names'])\n",
    "\n",
    "# G.add_nodes_from(video_ids, bipartite=0)  # First set (videos)\n",
    "# G.add_nodes_from(hashtags, bipartite=1)   # Second set (hashtags)\n",
    "\n",
    "# #for edges\n",
    "\n",
    "# for _, row in hashtag_df.iterrows():\n",
    "#     G.add_edge(row['id'], row['hashtag_names'])\n",
    "\n",
    "#FILTERED GRAPH\n",
    "G = nx.Graph()\n",
    "#for nodes\n",
    "\n",
    "video_ids = set(filtered_df['id'])\n",
    "hashtags = set(filtered_df['hashtag_names'])\n",
    "\n",
    "G.add_nodes_from(video_ids, bipartite=0)  # First set (videos)\n",
    "G.add_nodes_from(hashtags, bipartite=1)   # Second set (hashtags)\n",
    "\n",
    "#for edges\n",
    "\n",
    "for _, row in filtered_df.iterrows():\n",
    "    G.add_edge(row['id'], row['hashtag_names'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: create a bayesian graph for the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniparted network of hashtags\n",
    "\n",
    "Two hashtags are connected if they appeared in the same video.\n",
    "\n",
    "The edge weight represents how many times they co-occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# projecting to a unipartite graph of hashtags\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m HG \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mbipartite\u001b[38;5;241m.\u001b[39mweighted_projected_graph(G, hashtags, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m HG\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/networkx/utils/decorators.py:789\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 5:4\u001b[0m, in \u001b[0;36margmap_weighted_projected_graph_1\u001b[0;34m(B, nodes, ratio, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/networkx/utils/backends.py:633\u001b[0m, in \u001b[0;36m_dispatchable.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the result of the original function, or the backend function if\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03mthe backend is specified and that backend implements `func`.\"\"\"\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    636\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/networkx/algorithms/bipartite/projection.py:212\u001b[0m, in \u001b[0;36mweighted_projected_graph\u001b[0;34m(B, nodes, ratio)\u001b[0m\n\u001b[1;32m    210\u001b[0m nbrs2 \u001b[38;5;241m=\u001b[39m {n \u001b[38;5;28;01mfor\u001b[39;00m nbr \u001b[38;5;129;01min\u001b[39;00m unbrs \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m B[nbr]} \u001b[38;5;241m-\u001b[39m {u}\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m nbrs2:\n\u001b[0;32m--> 212\u001b[0m     vnbrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(pred[v])\n\u001b[1;32m    213\u001b[0m     common \u001b[38;5;241m=\u001b[39m unbrs \u001b[38;5;241m&\u001b[39m vnbrs\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ratio:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# projecting to a unipartite graph of hashtags\n",
    "HG = nx.bipartite.weighted_projected_graph(G, hashtags, ratio=False)\n",
    "HG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "nx.write_graphml(HG, \"filtered_bipartite.graphml\")\n",
    "\n",
    "# %%\n",
    "import pickle\n",
    "\n",
    "with open(\"filtered_bipartite.pkl\", \"wb\") as f:\n",
    "    pickle.dump(HG, f)\n",
    "\n",
    "# %%\n",
    "import csv\n",
    "\n",
    "edges_with_weights = HG.edges(data=True)\n",
    "\n",
    "# Open a CSV file to write\n",
    "with open(\"edgelist_unipartite_filtered.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Source\", \"Target\", \"Weight\"])  # Column headers\n",
    "    \n",
    "    # Write the edges and weights\n",
    "    for u, v, weight in edges_with_weights:\n",
    "        writer.writerow([u, v, weight['weight']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

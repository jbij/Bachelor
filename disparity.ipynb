{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('disparity.py', <http.client.HTTPMessage at 0x111c4dc50>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import urllib.request\n",
    "# url = \"https://raw.githubusercontent.com/DerwenAI/disparity_filter/main/disparity.py\"\n",
    "# urllib.request.urlretrieve(url, \"disparity.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import disparity\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_stats(G):\n",
    "    \"\"\"Returns various statistics of a given graph G.\"\"\"\n",
    "    stats = {}\n",
    "    stats['num_nodes'] = G.number_of_nodes()\n",
    "    stats['num_edges'] = G.number_of_edges()\n",
    "    stats['density'] = nx.density(G)\n",
    "    \n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    stats['mean_degree'] = np.mean(degrees)\n",
    "    stats['std_degree'] = np.std(degrees)\n",
    "    stats['global_clustering_coeff'] = nx.transitivity(G)\n",
    "    \n",
    "    stats['degree_assortativity'] = nx.degree_assortativity_coefficient(G)\n",
    "    \n",
    "    # Giant Connected Component (GCC)\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    GCC = G.subgraph(largest_cc)\n",
    "    stats['GCC_size'] = len(GCC)\n",
    "    \n",
    "    # Power-law fitting\n",
    "    try:\n",
    "        fit = powerlaw.Fit(degrees)\n",
    "        stats['power_law_alpha'] = fit.alpha  # Power-law exponent\n",
    "        stats['power_law_xmin'] = fit.xmin  # Minimum value where power law applies\n",
    "        stats['ks_test_statistic'] = fit.D  # KS test statistic (lower is better)\n",
    "        \n",
    "        # Compare power law with other distributions\n",
    "        distribution_list = ['lognormal', 'exponential', 'truncated_power_law']\n",
    "        comparison_results = {}\n",
    "        \n",
    "        for dist in distribution_list:\n",
    "            R, p = fit.distribution_compare('power_law', dist)\n",
    "            comparison_results[dist] = (R, p)\n",
    "        \n",
    "        # Find the best alternative distribution (lowest R and p-value)\n",
    "        best_fit = min(comparison_results.items(), key=lambda x: (x[1][0], x[1][1]))\n",
    "        best_dist, (best_R, best_p) = best_fit\n",
    "        \n",
    "        stats['best_powerlaw_comparison'] = f\"power law vs {best_dist}: R = {best_R:.3f}, p = {best_p:.3f}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        stats['power_law_test_error'] = str(e)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../shared-folder-gald/data/unipartite_og.pkl', \"rb\") as f:\n",
    "    HC = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_alpha_ptile=0.5\n",
    "# min_degree=2\n",
    "\n",
    "# alpha_measures = disparity.disparity_filter(HC)\n",
    "# quantiles, num_quant = disparity.calc_alpha_ptile(alpha_measures)\n",
    "# alpha_cutoff = quantiles[round(num_quant * min_alpha_ptile)]\n",
    "\n",
    "# disparity.cut_graph(HC, min_alpha_ptile, min_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def disparity_filter(G, alpha=0.05):\n",
    "#     \"\"\"\n",
    "#     Apply disparity filter to a weighted network to extract the backbone.\n",
    "\n",
    "#     Parameters:\n",
    "#         G (networkx.Graph): Weighted graph (can be directed or undirected)\n",
    "#         alpha (float): Significance level for edge filtering\n",
    "\n",
    "#     Returns:\n",
    "#         backbone (networkx.Graph): Backbone network with statistically significant edges\n",
    "#     \"\"\"\n",
    "#     if not nx.is_weighted(G):\n",
    "#         raise ValueError(\"Graph must be weighted.\")\n",
    "\n",
    "#     is_directed = G.is_directed()\n",
    "#     backbone = nx.DiGraph() if is_directed else nx.Graph()\n",
    "#     backbone.add_nodes_from(G.nodes(data=True))\n",
    "\n",
    "#     for node in G.nodes():\n",
    "#         neighbors = list(G[node])\n",
    "#         k = len(neighbors)\n",
    "#         if k <= 1:\n",
    "#             continue\n",
    "\n",
    "#         strength = sum(G[node][nbr].get(\"weight\", 1.0) for nbr in neighbors)\n",
    "\n",
    "#         for nbr in neighbors:\n",
    "#             w = G[node][nbr].get(\"weight\", 1.0)\n",
    "#             p_ij = w / strength\n",
    "#             alpha_ij = (1 - p_ij) ** (k - 1)\n",
    "\n",
    "#             # Test significance\n",
    "#             if alpha_ij < alpha:\n",
    "#                 if is_directed or not backbone.has_edge(nbr, node):\n",
    "#                     backbone.add_edge(node, nbr, weight=w)\n",
    "\n",
    "#     return backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = disparity_filter(HC, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_data = [\n",
    "    {'src': u, 'trg': v, 'nij': d['weight']}\n",
    "    for u, v, d in HC.edges(data=True)\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(edge_data)\n",
    "\n",
    "# Save to CSV\n",
    "# df.to_csv('HC_edgelist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbackboning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHC_edgelist.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m table, _, _ \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mread(df, triangular_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, column_of_interest \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, undirected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/bachelor/Bachelor/backboning.py:30\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, column_of_interest, triangular_input, consider_self_loops, undirected, drop_zeroes, sep)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filename, column_of_interest, triangular_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, consider_self_loops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, undirected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, drop_zeroes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m   \u001b[39m\u001b[38;5;124;03m\"\"\"Reads a field separated input file into the internal backboning format (a Pandas Dataframe).\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m   The input file should have three or more columns (default separator: tab).\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m   The input file must have a one line header with the column names.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m   The parsed network data, the number of nodes in the network and the number of edges.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m   \"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m    table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename, sep \u001b[38;5;241m=\u001b[39m sep)\n\u001b[1;32m     31\u001b[0m    table \u001b[38;5;241m=\u001b[39m table[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrg\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_of_interest]]\n\u001b[1;32m     32\u001b[0m    table\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {column_of_interest: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnij\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:704\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    701\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_binary_mode(path_or_buf, mode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    705\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:1163\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[0;34m(handle, mode)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   1164\u001b[0m     handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\n\u001b[1;32m   1165\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "import backboning as bb\n",
    "\n",
    "table, _, _ = bb.read(df, triangular_input = True, column_of_interest = 'weight', undirected = True, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating DF score...\n",
      "/Users/renatasapeta/Desktop/bachelor/Bachelor/backboning.py:184: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  table_sum = table.groupby(table[\"src\"]).sum().reset_index()\n",
      "/Users/renatasapeta/Desktop/bachelor/Bachelor/backboning.py:199: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"edge\", 1)\n",
      "/Users/renatasapeta/Desktop/bachelor/Bachelor/backboning.py:200: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"score_min\", 1)\n",
      "/Users/renatasapeta/Desktop/bachelor/Bachelor/backboning.py:201: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"variance_max\", 1)\n"
     ]
    }
   ],
   "source": [
    "disparity_applied = bb.disparity_filter(df, undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_applied = bb.thresholding(disparity_applied, threshold=0.95).drop(columns=[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = nx.from_pandas_edgelist(\n",
    "    thresh_applied,\n",
    "    source=\"src\",\n",
    "    target=\"trg\",\n",
    "    edge_attr=\"nij\",\n",
    "    create_using=nx.Graph()  # ensures it's undirected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "xmin progress: 99%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assuming nested distributions\n"
     ]
    }
   ],
   "source": [
    "HC_stats = graph_stats(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes - 93923\n",
      "num_edges - 1578479\n",
      "density - 0.00035787347976596543\n",
      "mean_degree - 33.61219296657901\n",
      "std_degree - 152.96947193302572\n",
      "global_clustering_coeff - 0.11255418217654023\n",
      "degree_assortativity - -0.06542236704138689\n",
      "GCC_size - 92258\n",
      "power_law_alpha - 2.4141039457565894\n",
      "power_law_xmin - 141.0\n",
      "ks_test_statistic - 0.01988228975623818\n",
      "best_powerlaw_comparison - power law vs truncated_power_law: R = -14.319, p = 0.000\n"
     ]
    }
   ],
   "source": [
    "for key, val in HC_stats.items():\n",
    "    print(key,'-', val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
